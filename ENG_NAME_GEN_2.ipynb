{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#0. 라이브러리 호출\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models import FastText\n",
    "import random\n",
    "import numpy as np\n",
    "import gensim\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. Pre-train 모델 호출\n",
    "# model = gensim.models.KeyedVectors.load_word2vec_format('./data/GoogleNews-vectors-negative300.bin', binary=True)  \n",
    "# model = FastText.load_fasttext_format('./data/wiki.simple/wiki.simple.bin')\n",
    "model = gensim.models.KeyedVectors.load_word2vec_format('./data/wiki-news/wiki-brooklyn.bin', binary=True, unicode_errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save_word2vec_format(\"wiki-brooklyn.bin\", binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('hate', 0.7127140760421753),\n",
       " ('loving', 0.7031040191650391),\n",
       " ('love-', 0.6824191808700562),\n",
       " ('loved', 0.6770628094673157),\n",
       " ('loves', 0.6755635738372803),\n",
       " ('passion', 0.6716182231903076),\n",
       " ('adore', 0.6669158935546875),\n",
       " ('LOVE', 0.6652414202690125),\n",
       " ('love.', 0.6644536256790161),\n",
       " ('affection', 0.6550436019897461),\n",
       " ('joy', 0.6524612307548523),\n",
       " ('longing', 0.6484255194664001),\n",
       " ('Love', 0.64578777551651),\n",
       " ('desire', 0.6282362341880798),\n",
       " ('lust', 0.6276705265045166),\n",
       " ('-love', 0.6259821057319641),\n",
       " ('devotion', 0.6211329698562622),\n",
       " ('lovers', 0.6190768480300903),\n",
       " ('love--and', 0.6178529858589172),\n",
       " ('love--', 0.6153439283370972),\n",
       " ('romance', 0.6132897734642029),\n",
       " ('lover', 0.6114474534988403),\n",
       " ('unrequited', 0.6062376499176025),\n",
       " ('cherish', 0.6042467355728149),\n",
       " ('friendship', 0.6021138429641724),\n",
       " ('looooove', 0.592999279499054),\n",
       " ('loooove', 0.5828747749328613),\n",
       " ('luv', 0.5823631286621094),\n",
       " ('passionate', 0.5786104202270508),\n",
       " ('admiration', 0.5778404474258423)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### 존재하지 않은 단어를 예측해보았다.\n",
    "query = 'love'\n",
    "\n",
    "if query in model.vocab:\n",
    "    mostRelated_with_score = model.most_similar(positive=query, topn=30) # awesome!\n",
    "else:\n",
    "    mostRelated_with_score = print('없어')\n",
    "    \n",
    "mostRelated_with_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hate',\n",
       " 'loving',\n",
       " 'love',\n",
       " 'loved',\n",
       " 'loves',\n",
       " 'passion',\n",
       " 'adore',\n",
       " 'LOVE',\n",
       " 'love',\n",
       " 'affection',\n",
       " 'joy',\n",
       " 'longing',\n",
       " 'Love',\n",
       " 'desire',\n",
       " 'lust',\n",
       " 'love',\n",
       " 'devotion',\n",
       " 'lovers',\n",
       " 'loveand',\n",
       " 'love',\n",
       " 'romance',\n",
       " 'lover',\n",
       " 'unrequited',\n",
       " 'cherish',\n",
       " 'friendship',\n",
       " 'looooove',\n",
       " 'loooove',\n",
       " 'luv',\n",
       " 'passionate',\n",
       " 'admiration']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mostRelated = []\n",
    "for word, score in mostRelated_with_score:\n",
    "    word2 = re.sub('[-=.#/?:$}]', '', word)\n",
    "    mostRelated.append(word2)\n",
    "\n",
    "mostRelated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RANDOM SAMPLING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brooklynlee/miniconda3/lib/python3.6/site-packages/ipykernel_launcher.py:3: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/Users/brooklynlee/miniconda3/lib/python3.6/site-packages/ipykernel_launcher.py:4: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "999994"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#2. 랜덤 샘플링을 위해 단어 사전 체크 --> 총 11만개 단어로 확인 \n",
    "\n",
    "type(model.wv.vocab) # dict 형태이더라\n",
    "fast_vocab_pre = model.wv.vocab\n",
    "# fast_vocab = fast_vocab_pre.keys()\n",
    "fast_vocab = list(fast_vocab_pre.keys())\n",
    "len(fast_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['boucherie', 'Scenarios', 'non-tendentious', 'billiard-table', 'niña']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#2-2. 랜덤 도전\n",
    "noRelated = random.sample(fast_vocab, 5)\n",
    "noRelated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# most_similar_cosmul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('castles', 1.2376798391342163),\n",
       " ('fortresses', 1.2096256017684937),\n",
       " ('fortress', 1.2063742876052856),\n",
       " ('tower', 1.187144160270691),\n",
       " ('fortifications', 1.1728166341781616),\n",
       " ('ramparts', 1.164400577545166),\n",
       " ('citadel', 1.1578179597854614),\n",
       " ('battlements', 1.1571522951126099),\n",
       " ('walls', 1.1314799785614014),\n",
       " ('ruins', 1.1080973148345947)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar_cosmul(positive=['towers', 'castle'], negative=['CityLine'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('loves', 1.181600570678711),\n",
       " ('liked', 1.1757943630218506),\n",
       " ('hated', 1.1353093385696411),\n",
       " ('hate', 1.1230437755584717),\n",
       " ('loving', 1.122377872467041),\n",
       " ('adored', 1.1118605136871338),\n",
       " ('LOVE', 1.08949875831604),\n",
       " ('admired', 1.0740004777908325),\n",
       " ('cared', 1.0570801496505737),\n",
       " ('want', 1.0436289310455322)]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_related= random.sample(mostRelated, 2)\n",
    "random_unrelated = random.sample(noRelated, 1)\n",
    "serendipity_score = model.most_similar_cosmul(positive=random_related, negative=random_unrelated)\n",
    "serendipity_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['loves',\n",
       " 'liked',\n",
       " 'hated',\n",
       " 'hate',\n",
       " 'loving',\n",
       " 'adored',\n",
       " 'LOVE',\n",
       " 'admired',\n",
       " 'cared',\n",
       " 'want']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "serendipity = []\n",
    "for word, score in serendipity_score:\n",
    "    word2 = re.sub('[=.#/?:$}]', '', word)\n",
    "    serendipity.append(word2)\n",
    "\n",
    "serendipity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# mostRelated+random 합치기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hate',\n",
       " 'loving',\n",
       " 'love',\n",
       " 'loved',\n",
       " 'loves',\n",
       " 'passion',\n",
       " 'adore',\n",
       " 'LOVE',\n",
       " 'love',\n",
       " 'affection',\n",
       " 'joy',\n",
       " 'longing',\n",
       " 'Love',\n",
       " 'desire',\n",
       " 'lust',\n",
       " 'love',\n",
       " 'devotion',\n",
       " 'lovers',\n",
       " 'loveand',\n",
       " 'love',\n",
       " 'romance',\n",
       " 'lover',\n",
       " 'unrequited',\n",
       " 'cherish',\n",
       " 'friendship',\n",
       " 'looooove',\n",
       " 'loooove',\n",
       " 'luv',\n",
       " 'passionate',\n",
       " 'admiration',\n",
       " 'loves',\n",
       " 'liked',\n",
       " 'hated',\n",
       " 'hate',\n",
       " 'loving',\n",
       " 'adored',\n",
       " 'LOVE',\n",
       " 'admired',\n",
       " 'cared',\n",
       " 'want']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_set = mostRelated + serendipity # + noRelated\n",
    "total_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MARKOV CHAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "syllable_seq = []\n",
    "\n",
    "for word in total_set:\n",
    "    split = list(word)\n",
    "    for i in range(len(split)-1):\n",
    "        syllable_seq.append((split[i], split[i+1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['c',\n",
       " 'i',\n",
       " 'k',\n",
       " 'l',\n",
       " 'j',\n",
       " 's',\n",
       " 'a',\n",
       " 'L',\n",
       " 'p',\n",
       " 'e',\n",
       " 'w',\n",
       " 'r',\n",
       " 't',\n",
       " 'O',\n",
       " 'h',\n",
       " 'E',\n",
       " 'o',\n",
       " 'y',\n",
       " 'm',\n",
       " 'v',\n",
       " 'V',\n",
       " 'f',\n",
       " 'd',\n",
       " 'n',\n",
       " 'u',\n",
       " 'g',\n",
       " 'q']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "syllable_dict_dup = []\n",
    "\n",
    "for i, j in syllable_seq:\n",
    "    syllable_dict_dup.append(i)\n",
    "    syllable_dict_dup.append(j)\n",
    "    \n",
    "# syllable_dict # 중복값의 향연\n",
    "syllable_dict = list(set(syllable_dict_dup))\n",
    "syllable_dict # 알파벳만 모음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('h', 'a'),\n",
       " ('a', 't'),\n",
       " ('t', 'e'),\n",
       " ('l', 'o'),\n",
       " ('o', 'v'),\n",
       " ('v', 'i'),\n",
       " ('i', 'n'),\n",
       " ('n', 'g'),\n",
       " ('l', 'o'),\n",
       " ('o', 'v'),\n",
       " ('v', 'e'),\n",
       " ('l', 'o'),\n",
       " ('o', 'v'),\n",
       " ('v', 'e'),\n",
       " ('e', 'd'),\n",
       " ('l', 'o'),\n",
       " ('o', 'v'),\n",
       " ('v', 'e'),\n",
       " ('e', 's'),\n",
       " ('p', 'a'),\n",
       " ('a', 's'),\n",
       " ('s', 's'),\n",
       " ('s', 'i'),\n",
       " ('i', 'o'),\n",
       " ('o', 'n'),\n",
       " ('a', 'd'),\n",
       " ('d', 'o'),\n",
       " ('o', 'r'),\n",
       " ('r', 'e'),\n",
       " ('L', 'O'),\n",
       " ('O', 'V'),\n",
       " ('V', 'E'),\n",
       " ('l', 'o'),\n",
       " ('o', 'v'),\n",
       " ('v', 'e'),\n",
       " ('a', 'f'),\n",
       " ('f', 'f'),\n",
       " ('f', 'e'),\n",
       " ('e', 'c'),\n",
       " ('c', 't'),\n",
       " ('t', 'i'),\n",
       " ('i', 'o'),\n",
       " ('o', 'n'),\n",
       " ('j', 'o'),\n",
       " ('o', 'y'),\n",
       " ('l', 'o'),\n",
       " ('o', 'n'),\n",
       " ('n', 'g'),\n",
       " ('g', 'i'),\n",
       " ('i', 'n'),\n",
       " ('n', 'g'),\n",
       " ('L', 'o'),\n",
       " ('o', 'v'),\n",
       " ('v', 'e'),\n",
       " ('d', 'e'),\n",
       " ('e', 's'),\n",
       " ('s', 'i'),\n",
       " ('i', 'r'),\n",
       " ('r', 'e'),\n",
       " ('l', 'u'),\n",
       " ('u', 's'),\n",
       " ('s', 't'),\n",
       " ('l', 'o'),\n",
       " ('o', 'v'),\n",
       " ('v', 'e'),\n",
       " ('d', 'e'),\n",
       " ('e', 'v'),\n",
       " ('v', 'o'),\n",
       " ('o', 't'),\n",
       " ('t', 'i'),\n",
       " ('i', 'o'),\n",
       " ('o', 'n'),\n",
       " ('l', 'o'),\n",
       " ('o', 'v'),\n",
       " ('v', 'e'),\n",
       " ('e', 'r'),\n",
       " ('r', 's'),\n",
       " ('l', 'o'),\n",
       " ('o', 'v'),\n",
       " ('v', 'e'),\n",
       " ('e', 'a'),\n",
       " ('a', 'n'),\n",
       " ('n', 'd'),\n",
       " ('l', 'o'),\n",
       " ('o', 'v'),\n",
       " ('v', 'e'),\n",
       " ('r', 'o'),\n",
       " ('o', 'm'),\n",
       " ('m', 'a'),\n",
       " ('a', 'n'),\n",
       " ('n', 'c'),\n",
       " ('c', 'e'),\n",
       " ('l', 'o'),\n",
       " ('o', 'v'),\n",
       " ('v', 'e'),\n",
       " ('e', 'r'),\n",
       " ('u', 'n'),\n",
       " ('n', 'r'),\n",
       " ('r', 'e'),\n",
       " ('e', 'q'),\n",
       " ('q', 'u'),\n",
       " ('u', 'i'),\n",
       " ('i', 't'),\n",
       " ('t', 'e'),\n",
       " ('e', 'd'),\n",
       " ('c', 'h'),\n",
       " ('h', 'e'),\n",
       " ('e', 'r'),\n",
       " ('r', 'i'),\n",
       " ('i', 's'),\n",
       " ('s', 'h'),\n",
       " ('f', 'r'),\n",
       " ('r', 'i'),\n",
       " ('i', 'e'),\n",
       " ('e', 'n'),\n",
       " ('n', 'd'),\n",
       " ('d', 's'),\n",
       " ('s', 'h'),\n",
       " ('h', 'i'),\n",
       " ('i', 'p'),\n",
       " ('l', 'o'),\n",
       " ('o', 'o'),\n",
       " ('o', 'o'),\n",
       " ('o', 'o'),\n",
       " ('o', 'o'),\n",
       " ('o', 'v'),\n",
       " ('v', 'e'),\n",
       " ('l', 'o'),\n",
       " ('o', 'o'),\n",
       " ('o', 'o'),\n",
       " ('o', 'o'),\n",
       " ('o', 'v'),\n",
       " ('v', 'e'),\n",
       " ('l', 'u'),\n",
       " ('u', 'v'),\n",
       " ('p', 'a'),\n",
       " ('a', 's'),\n",
       " ('s', 's'),\n",
       " ('s', 'i'),\n",
       " ('i', 'o'),\n",
       " ('o', 'n'),\n",
       " ('n', 'a'),\n",
       " ('a', 't'),\n",
       " ('t', 'e'),\n",
       " ('a', 'd'),\n",
       " ('d', 'm'),\n",
       " ('m', 'i'),\n",
       " ('i', 'r'),\n",
       " ('r', 'a'),\n",
       " ('a', 't'),\n",
       " ('t', 'i'),\n",
       " ('i', 'o'),\n",
       " ('o', 'n'),\n",
       " ('l', 'o'),\n",
       " ('o', 'v'),\n",
       " ('v', 'e'),\n",
       " ('e', 's'),\n",
       " ('l', 'i'),\n",
       " ('i', 'k'),\n",
       " ('k', 'e'),\n",
       " ('e', 'd'),\n",
       " ('h', 'a'),\n",
       " ('a', 't'),\n",
       " ('t', 'e'),\n",
       " ('e', 'd'),\n",
       " ('h', 'a'),\n",
       " ('a', 't'),\n",
       " ('t', 'e'),\n",
       " ('l', 'o'),\n",
       " ('o', 'v'),\n",
       " ('v', 'i'),\n",
       " ('i', 'n'),\n",
       " ('n', 'g'),\n",
       " ('a', 'd'),\n",
       " ('d', 'o'),\n",
       " ('o', 'r'),\n",
       " ('r', 'e'),\n",
       " ('e', 'd'),\n",
       " ('L', 'O'),\n",
       " ('O', 'V'),\n",
       " ('V', 'E'),\n",
       " ('a', 'd'),\n",
       " ('d', 'm'),\n",
       " ('m', 'i'),\n",
       " ('i', 'r'),\n",
       " ('r', 'e'),\n",
       " ('e', 'd'),\n",
       " ('c', 'a'),\n",
       " ('a', 'r'),\n",
       " ('r', 'e'),\n",
       " ('e', 'd'),\n",
       " ('w', 'a'),\n",
       " ('a', 'n'),\n",
       " ('n', 't')]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "syllable_seq # 알파벳 연속"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'L': ['O', 'o', 'O'],\n",
       " 'O': ['V', 'V'],\n",
       " 'V': ['E', 'E'],\n",
       " 'a': ['t',\n",
       "  's',\n",
       "  'd',\n",
       "  'f',\n",
       "  'n',\n",
       "  'n',\n",
       "  's',\n",
       "  't',\n",
       "  'd',\n",
       "  't',\n",
       "  't',\n",
       "  't',\n",
       "  'd',\n",
       "  'd',\n",
       "  'r',\n",
       "  'n'],\n",
       " 'c': ['t', 'e', 'h', 'a'],\n",
       " 'd': ['o', 'e', 'e', 's', 'm', 'o', 'm'],\n",
       " 'e': ['d',\n",
       "  's',\n",
       "  'c',\n",
       "  's',\n",
       "  'v',\n",
       "  'r',\n",
       "  'a',\n",
       "  'r',\n",
       "  'q',\n",
       "  'd',\n",
       "  'r',\n",
       "  'n',\n",
       "  's',\n",
       "  'd',\n",
       "  'd',\n",
       "  'd',\n",
       "  'd',\n",
       "  'd'],\n",
       " 'f': ['f', 'e', 'r'],\n",
       " 'g': ['i'],\n",
       " 'h': ['a', 'e', 'i', 'a', 'a'],\n",
       " 'i': ['n',\n",
       "  'o',\n",
       "  'o',\n",
       "  'n',\n",
       "  'r',\n",
       "  'o',\n",
       "  't',\n",
       "  's',\n",
       "  'e',\n",
       "  'p',\n",
       "  'o',\n",
       "  'r',\n",
       "  'o',\n",
       "  'k',\n",
       "  'n',\n",
       "  'r'],\n",
       " 'j': ['o'],\n",
       " 'k': ['e'],\n",
       " 'l': ['o',\n",
       "  'o',\n",
       "  'o',\n",
       "  'o',\n",
       "  'o',\n",
       "  'o',\n",
       "  'u',\n",
       "  'o',\n",
       "  'o',\n",
       "  'o',\n",
       "  'o',\n",
       "  'o',\n",
       "  'o',\n",
       "  'o',\n",
       "  'u',\n",
       "  'o',\n",
       "  'i',\n",
       "  'o'],\n",
       " 'm': ['a', 'i', 'i'],\n",
       " 'n': ['g', 'g', 'g', 'd', 'c', 'r', 'd', 'a', 'g', 't'],\n",
       " 'o': ['v',\n",
       "  'v',\n",
       "  'v',\n",
       "  'v',\n",
       "  'n',\n",
       "  'r',\n",
       "  'v',\n",
       "  'n',\n",
       "  'y',\n",
       "  'n',\n",
       "  'v',\n",
       "  'v',\n",
       "  't',\n",
       "  'n',\n",
       "  'v',\n",
       "  'v',\n",
       "  'v',\n",
       "  'm',\n",
       "  'v',\n",
       "  'o',\n",
       "  'o',\n",
       "  'o',\n",
       "  'o',\n",
       "  'v',\n",
       "  'o',\n",
       "  'o',\n",
       "  'o',\n",
       "  'v',\n",
       "  'n',\n",
       "  'n',\n",
       "  'v',\n",
       "  'v',\n",
       "  'r'],\n",
       " 'p': ['a', 'a'],\n",
       " 'q': ['u'],\n",
       " 'r': ['e', 'e', 's', 'o', 'e', 'i', 'i', 'a', 'e', 'e', 'e'],\n",
       " 's': ['s', 'i', 'i', 't', 'h', 'h', 's', 'i'],\n",
       " 't': ['e', 'i', 'i', 'e', 'e', 'i', 'e', 'e'],\n",
       " 'u': ['s', 'n', 'i', 'v'],\n",
       " 'v': ['i',\n",
       "  'e',\n",
       "  'e',\n",
       "  'e',\n",
       "  'e',\n",
       "  'e',\n",
       "  'e',\n",
       "  'o',\n",
       "  'e',\n",
       "  'e',\n",
       "  'e',\n",
       "  'e',\n",
       "  'e',\n",
       "  'e',\n",
       "  'e',\n",
       "  'i'],\n",
       " 'w': ['a']}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "syllable_seq_org = {}\n",
    "for word_1, word_2 in syllable_seq:\n",
    "    if word_1 in syllable_seq_org.keys():\n",
    "        syllable_seq_org[word_1].append(word_2)\n",
    "    else:\n",
    "        syllable_seq_org[word_1] = [word_2]\n",
    "        \n",
    "syllable_seq_org"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'n'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_word = np.random.choice(syllable_dict)\n",
    "first_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['n']"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = [first_word]\n",
    "n_words = 6\n",
    "chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(n_words):\n",
    "    if chain[-1] in syllable_seq_org: # KEY값이 존재하는지 확인한다.\n",
    "        ransam = np.random.choice(syllable_seq_org[chain[-1]])\n",
    "        chain.append(ransam)\n",
    "        \n",
    "# if 'b' in word_dict_fin:\n",
    "#    print(\"happy\")\n",
    "# else:\n",
    "#    print(\"sad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ngiersh'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fastthrough = ''.join(chain)\n",
    "fastthrough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-66-93c09622ffe5>, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-66-93c09622ffe5>\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    (([b-df-hj-np-tv-z])(?!\\2)){3}\u001b[0m\n\u001b[0m                         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 정규 표현식으로 자음의 연속 등은 좀 날려버리고 싶었다.\n",
    "(([b-df-hj-np-tv-z])(?!\\2)){3}\n",
    "\n",
    "re.findall('(([b-df-hj-np-tv-z])(?!\\2)){3}', fastthrough)\n",
    "\n",
    "#re.findall(r'[bcdfghjklmnpqrstvwxyz]+', fastthrough, re.IGNORECASE)\n",
    "#re.findall(r'[^aiueo]([aiueoAIUEO]{2,})(?=[^aiueo])', fastthrough)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 다시 fasttext에 넣기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brooklynlee/miniconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"word 'steredo' not in vocabulary\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-23c1fa4d6bd3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmostRelated_with_score_again\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmost_similar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpositive\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfastthrough\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtopn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/brooklynlee/miniconda3/lib/python3.6/site-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mmost_similar\u001b[0;34m(self, positive, negative, topn, restrict_vocab, indexer)\u001b[0m\n\u001b[1;32m    363\u001b[0m                 \u001b[0mmean\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 365\u001b[0;31m                 \u001b[0mmean\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_vec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_norm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    366\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    367\u001b[0m                     \u001b[0mall_words\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/brooklynlee/miniconda3/lib/python3.6/site-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mword_vec\u001b[0;34m(self, word, use_norm)\u001b[0m\n\u001b[1;32m    272\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 274\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"word '%s' not in vocabulary\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"word 'steredo' not in vocabulary\""
     ]
    }
   ],
   "source": [
    "mostRelated_with_score_again = model.wv.most_similar(positive=fastthrough, topn=30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mostRelated_with_score_again' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-88e5e4ca4c3b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmostRelated_with_score_again\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'mostRelated_with_score_again' is not defined"
     ]
    }
   ],
   "source": [
    "mostRelated_with_score_again"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def generate_similar(string):\n",
    "    # Generates similar name by substituting vowels\n",
    "    similar_word = []\n",
    "    for char in string:\n",
    "        if char.lower() in 'aeiou':\n",
    "           similar_word.append(random.choice(string.letters).lowercase())\n",
    "        else:\n",
    "            similar_word.append(char)\n",
    "    return ''.join(similar_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import random\n",
    "word = \"banana\"\n",
    "similar_word = []\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "for char in word:\n",
    "    if char.lower() in 'aeiou':\n",
    "        similar_word.append(random.choice(word).lower())\n",
    "    else:\n",
    "        similar_word.append(char)\n",
    "\n",
    "app = ''.join(similar_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bbnana'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "app"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 유사 키워드 중심 제너레이터\n",
    "\n",
    "### 키워드 포함 제너레이터\n",
    "\n",
    "### 랜덤 제너레이터\n",
    "\n",
    "##### 사람 이름 제너레이터 => 키워드에 boy, girl, man, girl, \n",
    "##### 병원 이름 제너레이터 => 키워드에 병원, 클리닉\n",
    "##### 카페 이름 제너레이터 => 카페, 커피, 아메리카노, 모카, 라떼\n",
    "##### 회사 이름 제너레이터 => 브랜드\n",
    "##### 상품 이름 제너레이터 => 브랜드\n",
    "\n",
    "키워드에서도 해당 이름"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('apples', 0.8038420677185059),\n",
       " ('pear', 0.7095531225204468),\n",
       " ('orchard', 0.6768797636032104),\n",
       " ('fruit', 0.667434811592102),\n",
       " ('pippin', 0.6674279570579529),\n",
       " ('Apple', 0.6574118733406067),\n",
       " ('Apples', 0.6510727405548096),\n",
       " ('pears', 0.6505748629570007),\n",
       " ('peach', 0.6391580104827881),\n",
       " ('Honeycrisp', 0.6376261711120605),\n",
       " ('berry', 0.6145990490913391),\n",
       " ('strawberry', 0.6060678958892822),\n",
       " ('cider', 0.6017017960548401),\n",
       " ('orchards', 0.5942728519439697),\n",
       " ('oranges', 0.589619517326355),\n",
       " ('blackberry', 0.5881143808364868),\n",
       " ('blueberry', 0.5859349966049194),\n",
       " ('juice', 0.5811988115310669),\n",
       " ('pome', 0.5808693766593933),\n",
       " ('clementine', 0.5797680616378784),\n",
       " ('pie', 0.5772964954376221),\n",
       " ('grape', 0.5769770741462708),\n",
       " ('mango', 0.5721451640129089),\n",
       " ('cherimoya', 0.569043755531311),\n",
       " ('banana', 0.5677878856658936)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aaa = [('apples', 0.8038420677185059), ('pear', 0.7095531225204468), ('orchard', 0.6768797636032104), ('fruit', 0.667434811592102), ('pippin', 0.6674279570579529), ('Apple', 0.6574118733406067), ('Apples', 0.6510727405548096), ('pears', 0.6505748629570007), ('peach', 0.6391580104827881), ('Honeycrisp', 0.6376261711120605), ('berry', 0.6145990490913391), ('strawberry', 0.6060678958892822), ('cider', 0.6017017960548401), ('orchards', 0.5942728519439697), ('oranges', 0.589619517326355), ('blackberry', 0.5881143808364868), ('blueberry', 0.5859349966049194), ('juice', 0.5811988115310669), ('pome', 0.5808693766593933), ('clementine', 0.5797680616378784), ('pie', 0.5772964954376221), ('grape', 0.5769770741462708), ('mango', 0.5721451640129089), ('cherimoya', 0.569043755531311), ('banana', 0.5677878856658936)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
